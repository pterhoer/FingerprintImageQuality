{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing FineNet\n",
    "Code for FineNet in paper \"Robust Minutiae Extractor: Integrating Deep Networks and Fingerprint Domain Knowledge\" at ICB 2018: https://arxiv.org/pdf/1712.09401.pdf\n",
    "\n",
    "If you use whole or partial function in this code, please cite paper:\n",
    "\n",
    "    @inproceedings{Nguyen_MinutiaeNet,\n",
    "\tauthor    = {Dinh-Luan Nguyen and Kai Cao and Anil K. Jain},\n",
    "\ttitle     = {Robust Minutiae Extractor: Integrating Deep Networks and Fingerprint Domain Knowledge},\n",
    "\tbooktitle = {The 11th International Conference on Biometrics, 2018},\n",
    "\tyear      = {2018},\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.realpath('../FineNet'))\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from FineNet.FineNet_model import FineNetmodel, plot_confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '7'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "\n",
    "\n",
    "# ============= Hyperparameters ===============\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "path_to_model = '../Models/FineNet.h5'\n",
    "input_shape = (224, 224, 3)\n",
    "# ============= end Hyperparameters ===============\n",
    "\n",
    "\n",
    "# =============== DATA loading ========================\n",
    "test_path = '../Dataset/test_sample/'\n",
    "\n",
    "# Feed data from directory into batches\n",
    "test_gen = ImageDataGenerator()\n",
    "test_batches = test_gen.flow_from_directory(test_path, target_size=(input_shape[0], input_shape[1]), classes=['minu', 'non_minu'], batch_size=batch_size, shuffle=False)\n",
    "# =============== end DATA loading ========================\n",
    "\n",
    "\n",
    "#============== Define model ==================\n",
    "model = FineNetmodel(num_classes = num_classes,\n",
    "                     pretrained_path = path_to_model,\n",
    "                     input_shape = input_shape)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0),\n",
    "              metrics=['accuracy'])\n",
    "#============== End define model ==============\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_batches)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "test_labels = test_batches.classes[test_batches.index_array]\n",
    "# ============= Plot confusion matrix ==================\n",
    "\n",
    "predictions = model.predict_generator(test_batches)\n",
    "\n",
    "cm = confusion_matrix(test_labels, np.argmax(predictions,axis=1))\n",
    "cm_plot_labels = ['minu','non_minu']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example predicting each patch\n",
    "Note: FineNet works correctly with 'nearest' setting in resize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can use this\n",
    "# from keras.preprocessing.image import load_img\n",
    "# image = load_img('../Dataset/samples/m2.jpg',target_size=(224,224))\n",
    "\n",
    "# or this\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('../Dataset/samples/patch.jpg')\n",
    "image = cv2.resize(image, dsize=(224, 224),interpolation=cv2.INTER_NEAREST)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "[class_idx] = np.argmax(model.predict(image),axis=1)\n",
    "print(class_idx)\n",
    "print(test_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpiqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
